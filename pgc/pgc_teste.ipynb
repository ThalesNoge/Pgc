{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1919f503-7ff9-43e5-979a-83459f7f1d4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'google.protobuf.descriptor' has no attribute '_internal_create_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mst\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, ImageEnhance\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatistics\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/streamlit/__init__.py:48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logger \u001b[38;5;28;01mas\u001b[39;00m _logger\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config \u001b[38;5;28;01mas\u001b[39;00m _config\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mRootContainer_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RootContainer\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msecrets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Secrets, SECRETS_FILE_LOC\n\u001b[1;32m     51\u001b[0m _LOGGER \u001b[38;5;241m=\u001b[39m _logger\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/streamlit/proto/RootContainer_pb2.py:22\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[1;32m     17\u001b[0m DESCRIPTOR \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mFileDescriptor(\n\u001b[1;32m     18\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreamlit/proto/RootContainer.proto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m   package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m   syntax\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproto3\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     21\u001b[0m   serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m---> 22\u001b[0m   create_key\u001b[38;5;241m=\u001b[39m\u001b[43m_descriptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_create_key\u001b[49m,\n\u001b[1;32m     23\u001b[0m   serialized_pb\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m#streamlit/proto/RootContainer.proto*&\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124mRootContainer\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x08\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x04\u001b[39;00m\u001b[38;5;124mMAIN\u001b[39m\u001b[38;5;130;01m\\x10\u001b[39;00m\u001b[38;5;130;01m\\x00\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x0b\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x07\u001b[39;00m\u001b[38;5;124mSIDEBAR\u001b[39m\u001b[38;5;130;01m\\x10\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;130;01m\\x62\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[38;5;124mproto3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m _ROOTCONTAINER \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mEnumDescriptor(\n\u001b[1;32m     27\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRootContainer\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     28\u001b[0m   full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRootContainer\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m   serialized_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m77\u001b[39m,\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     49\u001b[0m _sym_db\u001b[38;5;241m.\u001b[39mRegisterEnumDescriptor(_ROOTCONTAINER)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'google.protobuf.descriptor' has no attribute '_internal_create_key'"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from PIL import Image, ImageEnhance\n",
    "import statistics\n",
    "import os\n",
    "import string\n",
    "from collections import Counter \n",
    "from itertools import tee, count\n",
    "# import TDTSR\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "# from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "# from cv2 import dnn_superres\n",
    "from transformers import DetrFeatureExtractor\n",
    "#from transformers import DetrForObjectDetection\n",
    "from transformers import TableTransformerForObjectDetection\n",
    "import torch\n",
    "import asyncio\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "\n",
    "st.set_option('deprecation.showPyplotGlobalUse', False)\n",
    "st.set_page_config(layout='wide')\n",
    "st.title(\"Table Detection and Table Structure Recognition\")\n",
    "st.write(\"Implemented by MSFT team: https://github.com/microsoft/table-transformer\")\n",
    "\n",
    "\n",
    "\n",
    "def PIL_to_cv(pil_img):\n",
    "    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR) \n",
    "\n",
    "def cv_to_PIL(cv_img):\n",
    "    return Image.fromarray(cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\n",
    "async def pytess(cell_pil_img):\n",
    "    return ' '.join(pytesseract.image_to_data(cell_pil_img, output_type=Output.DICT, config='-c tessedit_char_blacklist=œ˜â€œï¬â™Ã©œ¢!|”?«“¥ --psm 6 preserve_interword_spaces')['text']).strip()\n",
    "\n",
    "\n",
    "# def super_res(pil_img):\n",
    "    # '''\n",
    "    # Useful for low-res docs\n",
    "    # '''\n",
    "    # requires opencv-contrib-python installed without the opencv-python\n",
    "    # sr = dnn_superres.DnnSuperResImpl_create()\n",
    "    # image = PIL_to_cv(pil_img)\n",
    "    # model_path = \"/data/Salman/TRD/code/table-transformer/transformers/LapSRN_x2.pb\"\n",
    "    # model_name = 'lapsrn'\n",
    "    # model_scale = 2\n",
    "    # sr.readModel(model_path)\n",
    "    # sr.setModel(model_name, model_scale)\n",
    "    # final_img = sr.upsample(image)\n",
    "    # final_img = cv_to_PIL(final_img)\n",
    "\n",
    "    # return final_img\n",
    "\n",
    "\n",
    "def sharpen_image(pil_img):\n",
    "\n",
    "    img = PIL_to_cv(pil_img)\n",
    "    sharpen_kernel = np.array([[-1, -1, -1], \n",
    "                               [-1,  9, -1], \n",
    "                               [-1, -1, -1]])\n",
    "\n",
    "    sharpen = cv2.filter2D(img, -1, sharpen_kernel)\n",
    "    pil_img = cv_to_PIL(sharpen)\n",
    "    return pil_img\n",
    "\n",
    "\n",
    "def uniquify(seq, suffs = count(1)):\n",
    "    \"\"\"Make all the items unique by adding a suffix (1, 2, etc).\n",
    "    Credit: https://stackoverflow.com/questions/30650474/python-rename-duplicates-in-list-with-progressive-numbers-without-sorting-list\n",
    "    `seq` is mutable sequence of strings.\n",
    "    `suffs` is an optional alternative suffix iterable.\n",
    "    \"\"\"\n",
    "    not_unique = [k for k,v in Counter(seq).items() if v>1] \n",
    "\n",
    "    suff_gens = dict(zip(not_unique, tee(suffs, len(not_unique))))  \n",
    "    for idx,s in enumerate(seq):\n",
    "        try:\n",
    "            suffix = str(next(suff_gens[s]))\n",
    "        except KeyError:\n",
    "            continue\n",
    "        else:\n",
    "            seq[idx] += suffix\n",
    "\n",
    "    return seq\n",
    "\n",
    "def binarizeBlur_image(pil_img):\n",
    "    image = PIL_to_cv(pil_img)\n",
    "    thresh = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "    result = cv2.GaussianBlur(thresh, (5,5), 0)\n",
    "    result = 255 - result\n",
    "    return cv_to_PIL(result)\n",
    "\n",
    "\n",
    "\n",
    "def td_postprocess(pil_img):\n",
    "    '''\n",
    "    Removes gray background from tables\n",
    "    '''\n",
    "    img = PIL_to_cv(pil_img)\n",
    "\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, (0, 0, 100), (255, 5, 255)) # (0, 0, 100), (255, 5, 255)\n",
    "    nzmask = cv2.inRange(hsv, (0, 0, 5), (255, 255, 255)) # (0, 0, 5), (255, 255, 255))\n",
    "    nzmask = cv2.erode(nzmask, np.ones((3,3))) # (3,3)\n",
    "    mask = mask & nzmask\n",
    "\n",
    "    new_img = img.copy()\n",
    "    new_img[np.where(mask)] = 255\n",
    "\n",
    "\n",
    "    return cv_to_PIL(new_img)\n",
    "\n",
    "# def super_res(pil_img):\n",
    "#     # requires opencv-contrib-python installed without the opencv-python\n",
    "#     sr = dnn_superres.DnnSuperResImpl_create()\n",
    "#     image = PIL_to_cv(pil_img)\n",
    "#     model_path = \"./LapSRN_x8.pb\"\n",
    "#     model_name = model_path.split('/')[1].split('_')[0].lower()\n",
    "#     model_scale = int(model_path.split('/')[1].split('_')[1].split('.')[0][1])\n",
    "\n",
    "#     sr.readModel(model_path)\n",
    "#     sr.setModel(model_name, model_scale)\n",
    "#     final_img = sr.upsample(image)\n",
    "#     final_img = cv_to_PIL(final_img)\n",
    "\n",
    "#     return final_img\n",
    "\n",
    "def table_detector(image, THRESHOLD_PROBA):\n",
    "    '''\n",
    "    Table detection using DEtect-object TRansformer pre-trained on 1 million tables\n",
    "\n",
    "    '''\n",
    "\n",
    "    feature_extractor = DetrFeatureExtractor(do_resize=True, size=800, max_size=800)\n",
    "    encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "\n",
    "    model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-detection\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "\n",
    "    probas = outputs.logits.softmax(-1)[0, :, :-1]\n",
    "    keep = probas.max(-1).values > THRESHOLD_PROBA\n",
    "\n",
    "    target_sizes = torch.tensor(image.size[::-1]).unsqueeze(0)\n",
    "    postprocessed_outputs = feature_extractor.post_process(outputs, target_sizes)\n",
    "    bboxes_scaled = postprocessed_outputs[0]['boxes'][keep]\n",
    "\n",
    "    return (model, probas[keep], bboxes_scaled)\n",
    "\n",
    "\n",
    "def table_struct_recog(image, THRESHOLD_PROBA):\n",
    "    '''\n",
    "    Table structure recognition using DEtect-object TRansformer pre-trained on 1 million tables\n",
    "    '''\n",
    "\n",
    "    feature_extractor = DetrFeatureExtractor(do_resize=True, size=1000, max_size=1000)\n",
    "    encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "\n",
    "    model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-structure-recognition\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "\n",
    "    probas = outputs.logits.softmax(-1)[0, :, :-1]\n",
    "    keep = probas.max(-1).values > THRESHOLD_PROBA\n",
    "\n",
    "    target_sizes = torch.tensor(image.size[::-1]).unsqueeze(0)\n",
    "    postprocessed_outputs = feature_extractor.post_process(outputs, target_sizes)\n",
    "    bboxes_scaled = postprocessed_outputs[0]['boxes'][keep]\n",
    "\n",
    "    return (model, probas[keep], bboxes_scaled)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TableExtractionPipeline():\n",
    "\n",
    "    colors = [\"red\", \"blue\", \"green\", \"yellow\", \"orange\", \"violet\"]\n",
    "\n",
    "    # colors = [\"red\", \"blue\", \"green\", \"red\", \"red\", \"red\"]\n",
    "\n",
    "    def add_padding(self, pil_img, top, right, bottom, left, color=(255,255,255)):\n",
    "        '''\n",
    "        Image padding as part of TSR pre-processing to prevent missing table edges\n",
    "        '''\n",
    "        width, height = pil_img.size\n",
    "        new_width = width + right + left\n",
    "        new_height = height + top + bottom\n",
    "        result = Image.new(pil_img.mode, (new_width, new_height), color)\n",
    "        result.paste(pil_img, (left, top))\n",
    "        return result\n",
    "\n",
    "    def plot_results_detection(self, c1, model, pil_img, prob, boxes, delta_xmin, delta_ymin, delta_xmax, delta_ymax):\n",
    "        '''\n",
    "        crop_tables and plot_results_detection must have same co-ord shifts because 1 only plots the other one updates co-ordinates \n",
    "        '''\n",
    "        # st.write('img_obj')\n",
    "        # st.write(pil_img)\n",
    "        plt.imshow(pil_img)\n",
    "        ax = plt.gca()\n",
    "\n",
    "        for p, (xmin, ymin, xmax, ymax) in zip(prob, boxes.tolist()):\n",
    "            cl = p.argmax()\n",
    "            xmin, ymin, xmax, ymax = xmin-delta_xmin, ymin-delta_ymin, xmax+delta_xmax, ymax+delta_ymax \n",
    "            a\n",
    "            text = f'{model.config.id2label[cl.item()]}: {p[cl]:0.2f}'\n",
    "            ax.text(xmin-20, ymin-50, text, fontsize=10,bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "        plt.axis('off')\n",
    "        c1.pyplot()\n",
    "\n",
    "\n",
    "    def crop_tables(self, pil_img, prob, boxes, delta_xmin, delta_ymin, delta_xmax, delta_ymax):\n",
    "        '''\n",
    "        crop_tables and plot_results_detection must have same co-ord shifts because 1 only plots the other one updates co-ordinates \n",
    "        '''\n",
    "        cropped_img_list = []\n",
    "\n",
    "        for p, (xmin, ymin, xmax, ymax) in zip(prob, boxes.tolist()):\n",
    "\n",
    "            xmin, ymin, xmax, ymax = xmin-delta_xmin, ymin-delta_ymin, xmax+delta_xmax, ymax+delta_ymax \n",
    "            cropped_img = pil_img.crop((xmin, ymin, xmax, ymax))\n",
    "            cropped_img_list.append(cropped_img)\n",
    "\n",
    "\n",
    "        return cropped_img_list\n",
    "\n",
    "    def generate_structure(self, c2, model, pil_img, prob, boxes, expand_rowcol_bbox_top, expand_rowcol_bbox_bottom):\n",
    "        '''\n",
    "        Co-ordinates are adjusted here by 3 'pixels'\n",
    "        To plot table pillow image and the TSR bounding boxes on the table\n",
    "        '''\n",
    "        # st.write('img_obj')\n",
    "        # st.write(pil_img)\n",
    "        plt.figure(figsize=(32,20))\n",
    "        plt.imshow(pil_img)\n",
    "        ax = plt.gca()\n",
    "        rows = {}\n",
    "        cols = {}\n",
    "        idx = 0\n",
    "\n",
    "\n",
    "        for p, (xmin, ymin, xmax, ymax) in zip(prob, boxes.tolist()):\n",
    "\n",
    "            xmin, ymin, xmax, ymax = xmin, ymin, xmax, ymax \n",
    "            cl = p.argmax()\n",
    "            class_text = model.config.id2label[cl.item()]\n",
    "            text = f'{class_text}: {p[cl]:0.2f}'\n",
    "            # or (class_text == 'table column')\n",
    "            if (class_text == 'table row')  or (class_text =='table projected row header') or (class_text == 'table column'):\n",
    "                ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,fill=False, color=self.colors[cl.item()], linewidth=2))\n",
    "                ax.text(xmin-10, ymin-10, text, fontsize=5, bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "\n",
    "            if class_text == 'table row':\n",
    "                rows['table row.'+str(idx)] = (xmin, ymin-expand_rowcol_bbox_top, xmax, ymax+expand_rowcol_bbox_bottom)\n",
    "            if class_text == 'table column':\n",
    "                cols['table column.'+str(idx)] = (xmin, ymin-expand_rowcol_bbox_top, xmax, ymax+expand_rowcol_bbox_bottom)\n",
    "\n",
    "            idx += 1\n",
    "\n",
    "\n",
    "        plt.axis('on')\n",
    "        c2.pyplot()\n",
    "        return rows, cols\n",
    "\n",
    "    def sort_table_featuresv2(self, rows:dict, cols:dict):\n",
    "        # Sometimes the header and first row overlap, and we need the header bbox not to have first row's bbox inside the headers bbox\n",
    "        rows_ = {table_feature : (xmin, ymin, xmax, ymax) for table_feature, (xmin, ymin, xmax, ymax) in sorted(rows.items(), key=lambda tup: tup[1][1])}\n",
    "        cols_ = {table_feature : (xmin, ymin, xmax, ymax) for table_feature, (xmin, ymin, xmax, ymax) in sorted(cols.items(), key=lambda tup: tup[1][0])}\n",
    "\n",
    "        return rows_, cols_\n",
    "\n",
    "    def individual_table_featuresv2(self, pil_img, rows:dict, cols:dict):\n",
    "\n",
    "        for k, v in rows.items():\n",
    "            xmin, ymin, xmax, ymax = v\n",
    "            cropped_img = pil_img.crop((xmin, ymin, xmax, ymax))\n",
    "            rows[k] = xmin, ymin, xmax, ymax, cropped_img\n",
    "\n",
    "        for k, v in cols.items():\n",
    "            xmin, ymin, xmax, ymax = v\n",
    "            cropped_img = pil_img.crop((xmin, ymin, xmax, ymax))\n",
    "            cols[k] = xmin, ymin, xmax, ymax, cropped_img\n",
    "\n",
    "        return rows, cols\n",
    "\n",
    "\n",
    "    def object_to_cellsv2(self, master_row:dict, cols:dict, expand_rowcol_bbox_top, expand_rowcol_bbox_bottom, padd_left):\n",
    "        '''Removes redundant bbox for rows&columns and divides each row into cells from columns\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        \n",
    "        '''\n",
    "        cells_img = {}\n",
    "        header_idx = 0\n",
    "        row_idx = 0\n",
    "        previous_xmax_col = 0\n",
    "        new_cols = {}\n",
    "        new_master_row = {}\n",
    "        previous_ymin_row = 0\n",
    "        new_cols = cols\n",
    "        new_master_row = master_row\n",
    "        ## Below 2 for loops remove redundant bounding boxes ###\n",
    "        # for k_col, v_col in cols.items():\n",
    "        #     xmin_col, _, xmax_col, _, col_img = v_col\n",
    "        #     if (np.isclose(previous_xmax_col, xmax_col, atol=5)) or (xmin_col >= xmax_col):\n",
    "        #         print('Found a column with double bbox')\n",
    "        #         continue\n",
    "        #     previous_xmax_col = xmax_col\n",
    "        #     new_cols[k_col] = v_col\n",
    "\n",
    "        # for k_row, v_row in master_row.items():\n",
    "        #     _, ymin_row, _, ymax_row, row_img = v_row\n",
    "        #     if (np.isclose(previous_ymin_row, ymin_row, atol=5)) or (ymin_row >= ymax_row):\n",
    "        #         print('Found a row with double bbox')\n",
    "        #         continue\n",
    "        #     previous_ymin_row = ymin_row\n",
    "        #     new_master_row[k_row] = v_row\n",
    "        ######################################################\n",
    "        for k_row, v_row in new_master_row.items():\n",
    "            \n",
    "            _, _, _, _, row_img = v_row\n",
    "            xmax, ymax = row_img.size\n",
    "            xa, ya, xb, yb = 0, 0, 0, ymax\n",
    "            row_img_list = []\n",
    "            # plt.imshow(row_img)\n",
    "            # st.pyplot()\n",
    "            for idx, kv in enumerate(new_cols.items()):\n",
    "                k_col, v_col = kv\n",
    "                xmin_col, _, xmax_col, _, col_img = v_col\n",
    "                xmin_col, xmax_col = xmin_col - padd_left - 10, xmax_col - padd_left\n",
    "                # plt.imshow(col_img)\n",
    "                # st.pyplot()\n",
    "                # xa + 3 : to remove borders on the left side of the cropped cell\n",
    "                # yb = 3: to remove row information from the above row of the cropped cell\n",
    "                # xb - 3: to remove borders on the right side of the cropped cell\n",
    "                xa = xmin_col\n",
    "                xb = xmax_col\n",
    "                if idx == 0:\n",
    "                    xa = 0\n",
    "                if idx == len(new_cols)-1:\n",
    "                    xb = xmax\n",
    "                xa, ya, xb, yb = xa, ya, xb, yb\n",
    "\n",
    "                row_img_cropped = row_img.crop((xa, ya, xb, yb))\n",
    "                row_img_list.append(row_img_cropped)\n",
    "\n",
    "            cells_img[k_row+'.'+str(row_idx)] = row_img_list\n",
    "            row_idx += 1\n",
    "\n",
    "        return cells_img, len(new_cols), len(new_master_row)-1\n",
    "\n",
    "    def clean_dataframe(self, df):\n",
    "        '''\n",
    "        Remove irrelevant symbols that appear with tesseractOCR\n",
    "        '''\n",
    "        # df.columns = [col.replace('|', '') for col in df.columns]\n",
    "\n",
    "        for col in df.columns:\n",
    "\n",
    "            df[col]=df[col].str.replace(\"'\", '', regex=True)\n",
    "            df[col]=df[col].str.replace('\"', '', regex=True)\n",
    "            df[col]=df[col].str.replace(']', '', regex=True)\n",
    "            df[col]=df[col].str.replace('[', '', regex=True)\n",
    "            df[col]=df[col].str.replace('{', '', regex=True)\n",
    "            df[col]=df[col].str.replace('}', '', regex=True)\n",
    "        return df\n",
    "\n",
    "    @st.cache\n",
    "    def convert_df(self, df):\n",
    "        return df.to_csv().encode('utf-8')\n",
    "\n",
    "\n",
    "    def create_dataframe(self, c3, cells_pytess_result:list, max_cols:int, max_rows:int):\n",
    "        '''Create dataframe using list of cell values of the table, also checks for valid header of dataframe\n",
    "        Args:\n",
    "            cells_pytess_result: list of strings, each element representing a cell in a table\n",
    "            max_cols, max_rows: number of columns and rows\n",
    "        Returns:\n",
    "            dataframe : final dataframe after all pre-processing \n",
    "        '''\n",
    "\n",
    "        headers = cells_pytess_result[:max_cols]\n",
    "        new_headers = uniquify(headers, (f' {x!s}' for x in string.ascii_lowercase))\n",
    "        counter = 0\n",
    "\n",
    "        cells_list = cells_pytess_result[max_cols:]\n",
    "        df = pd.DataFrame(\"\", index=range(0, max_rows), columns=new_headers)\n",
    "\n",
    "        cell_idx = 0\n",
    "        for nrows in range(max_rows):\n",
    "            for ncols in range(max_cols):\n",
    "                df.iat[nrows, ncols] = str(cells_list[cell_idx])\n",
    "                cell_idx += 1\n",
    "\n",
    "        ## To check if there are duplicate headers if result of uniquify+col == col \n",
    "        ## This check removes headers when all headers are empty or if median of header word count is less than 6\n",
    "        for x, col in zip(string.ascii_lowercase, new_headers):\n",
    "            if f' {x!s}' == col:\n",
    "                counter += 1\n",
    "        header_char_count = [len(col) for col in new_headers]\n",
    "\n",
    "        # if (counter == len(new_headers)) or (statistics.median(header_char_count) < 6):\n",
    "        #     st.write('woooot')\n",
    "        #     df.columns = uniquify(df.iloc[0], (f' {x!s}' for x in string.ascii_lowercase))\n",
    "        #     df = df.iloc[1:,:]\n",
    "\n",
    "        df = self.clean_dataframe(df)\n",
    "        \n",
    "        c3.dataframe(df)\n",
    "        csv = self.convert_df(df)\n",
    "        c3.download_button(\"Download table\", csv, \"file.csv\", \"text/csv\", key='download-csv')\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    async def start_process(self, image_path:str, TD_THRESHOLD, TSR_THRESHOLD, padd_top, padd_left, padd_bottom, padd_right, delta_xmin, delta_ymin, delta_xmax, delta_ymax, expand_rowcol_bbox_top, expand_rowcol_bbox_bottom):\n",
    "        '''\n",
    "        Initiates process of generating pandas dataframes from raw pdf-page images\n",
    "\n",
    "        '''\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        model, probas, bboxes_scaled = table_detector(image, THRESHOLD_PROBA=TD_THRESHOLD)\n",
    "\n",
    "        if bboxes_scaled.nelement() == 0:\n",
    "            st.write('No table found in the pdf-page image')\n",
    "            return ''\n",
    "        \n",
    "        # try:\n",
    "        # st.write('Document: '+image_path.split('/')[-1])\n",
    "        c1, c2, c3 = st.columns((1,1,1))\n",
    "\n",
    "        self.plot_results_detection(c1, model, image, probas, bboxes_scaled,  delta_xmin, delta_ymin, delta_xmax, delta_ymax) \n",
    "        cropped_img_list = self.crop_tables(image, probas, bboxes_scaled, delta_xmin, delta_ymin, delta_xmax, delta_ymax)\n",
    "\n",
    "        for unpadded_table in cropped_img_list:\n",
    "\n",
    "            table = self.add_padding(unpadded_table, padd_top, padd_right, padd_bottom, padd_left)\n",
    "            # table = super_res(table)\n",
    "            # table = binarizeBlur_image(table)\n",
    "            # table = sharpen_image(table) # Test sharpen image next\n",
    "            # table = td_postprocess(table)\n",
    "\n",
    "            model, probas, bboxes_scaled = table_struct_recog(table, THRESHOLD_PROBA=TSR_THRESHOLD)\n",
    "            rows, cols = self.generate_structure(c2, model, table, probas, bboxes_scaled, expand_rowcol_bbox_top, expand_rowcol_bbox_bottom)\n",
    "            # st.write(len(rows), len(cols))\n",
    "            rows, cols = self.sort_table_featuresv2(rows, cols)\n",
    "            master_row, cols = self.individual_table_featuresv2(table, rows, cols)\n",
    "\n",
    "            cells_img, max_cols, max_rows = self.object_to_cellsv2(master_row, cols, expand_rowcol_bbox_top, expand_rowcol_bbox_bottom, padd_left)\n",
    "\n",
    "            sequential_cell_img_list = []\n",
    "            for k, img_list in cells_img.items():\n",
    "                for img in img_list:\n",
    "                    # img = super_res(img)\n",
    "                    # img = sharpen_image(img) # Test sharpen image next\n",
    "                    # img = binarizeBlur_image(img)\n",
    "                    # img = self.add_padding(img, 10,10,10,10)\n",
    "                    # plt.imshow(img)\n",
    "                    # c3.pyplot()\n",
    "                    sequential_cell_img_list.append(pytess(img))\n",
    "\n",
    "            cells_pytess_result = await asyncio.gather(*sequential_cell_img_list)\n",
    "            \n",
    "\n",
    "            self.create_dataframe(c3, cells_pytess_result, max_cols, max_rows)\n",
    "            st.write('Errors in OCR is due to either quality of the image or performance of the OCR')\n",
    "        # except:\n",
    "        #     st.write('Either incorrectly identified table or no table, to debug remove try/except')\n",
    "            # break\n",
    "        # break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    img_name = st.file_uploader(\"Upload an image with table(s)\")\n",
    "    st1, st2 = st.columns((1,1))\n",
    "    TD_th = st1.slider('Table detection threshold', 0.0, 1.0, 0.6)\n",
    "    TSR_th = st2.slider('Table structure recognition threshold', 0.0, 1.0, 0.8)\n",
    "\n",
    "    st1, st2, st3, st4 = st.columns((1,1,1,1))\n",
    "\n",
    "    padd_top = st1.slider('Padding top', 0, 200, 20)\n",
    "    padd_left = st2.slider('Padding left', 0, 200, 20)\n",
    "    padd_right = st3.slider('Padding right', 0, 200, 20)\n",
    "    padd_bottom = st4.slider('Padding bottom', 0, 200, 20)\n",
    "\n",
    "    te = TableExtractionPipeline()\n",
    "    # for img in image_list:\n",
    "    if img_name is not None:\n",
    "        asyncio.run(te.start_process(img_name, TD_THRESHOLD=TD_th , TSR_THRESHOLD=TSR_th , padd_top=padd_top, padd_left=padd_left, padd_bottom=padd_bottom, padd_right=padd_right, delta_xmin=0, delta_ymin=0, delta_xmax=0, delta_ymax=0, expand_rowcol_bbox_top=0, expand_rowcol_bbox_bottom=0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad30721-65cf-45e1-b69d-f7601bd50871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
